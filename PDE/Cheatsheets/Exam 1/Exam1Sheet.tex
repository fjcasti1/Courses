\documentclass[6pt]{article}
\usepackage{amsmath, amssymb}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{multicol}

%\usepackage[font={small}, margin=1cm]{caption}
\usepackage[margin=.1in]{geometry}
\setlength{\parindent}{0pt}
\renewcommand{\arraystretch}{0.8}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\ra}{\rightarrow}


\begin{document}
\fontsize{8}{10}
\selectfont
\begin{multicols}{2}
This PDE, $\sum_{j=1}^n a_j(x,u(x))\partial u/\partial x_j(x)=c(x,u(x))$, is called {\bf quasilinear} if the solution $u$ appears in the coefficients $a_j$ which multiply the partial derivatives of $u$. 
If $u$ is not in $a_j$, but appears in $c$ in a nonlinear way like $c(x,u)=\gamma(x)u^2$ or $c(x,u)=\gamma(x)e^u$, the PDE is called {\bf semilinear}. If $u$ appears linearly in $c$ like $c(x,u)= \gamma(x)u$, the PDE is called {\bf homogeneous linear}.  If $u$ appears in $c$ like $c(x,u)=\gamma(x)u+\tilde{\gamma}(x)$, then the PDE is called {\bf inhomogeneous linear}. The heat equation $u_t=cu_{xx}+f(x,t)$ is a linear {\bf parabolic} PDE. The wave equation $u_{tt}=c^2 u_{xx}+f(x,t)$ is a linear {\bf hyperbolic} PDE. The Poisson equation, $\Delta u + f(x)=0$, is an {\bf elliptic} PDE. $\Delta u=u_{xx}$.
% Proposition 3.1
{\bf 3.1P} Let $u$ be a solution of $\sum_{j=1}^n a_j(x,u(x))\partial_ju(x)=c(x,u(x))$ and let $u, a_j$ and $c$ be continuously differentiable.  Let $\xi_1, \dots \xi_n, v: I\ra \R$ be a solution of the ODE system $\xi_j'=a_j(\xi,v), j=1, \dots n, v'=c(\xi,v)$, where $\xi(t)=(\xi_1(t), \dots, \xi_n(t))$ and $I$ some interval.  Then $v(t)=u(\xi(t))$ for all $t \in I$, if it holds for at least one $t_0 \in I$.
% Example 3.4
{\bf Example3.4}. Find a solution $u$ of two real variables $x,y$ to $xu_x+(x+y)u_y=u+1, u(x,0)=x^2$. Solution.  In the language used before, this is $x_1\partial_1u+(x_1+x_2)\partial_2u=u+1, u(x_1,0)=x_1^2$, a nonhomogeneous linear PDE.  We identify the hypersurface $S=\{(x,0); x \in \R\}$. So $S=g(\R)$ with $g(z)=(z,0)$. We further identify $u_0(z,0)=z^2, z\in \R$.  The characteristic system is $\partial_t\xi_1=\xi_1, \partial_t\xi_2=\xi_1+\xi_2, \partial_tv=v+1$, with the initial conditions $\xi_1(z,0)=z, \xi_2(z,0)=0, v(z,0)=z^2$. We integrate the equation for $\xi_1, \xi_1(z,t)=ze^t$. We substitute this into the differential equation for $\xi_2, \partial_t=ze^t+\xi_2$. Recall the variation of constants formula or use an integrating factor. Since $\xi_2(z,0)=0, \xi_2(z,t)=\int_0^t ze^se^{t-s}ds=tze^t$. By the same token, $v(z,t)=v(z,0)e^t+\int_0^te^sds=z^2e^t+e^t-1$, or set $w=v+1, \partial_t w=w, w(z,0)=z^2+1, w(z,t)=(z^2+1)e^t, v(z,t)=(z^2+1)e^t-1$. In order to find $u$ with $v(z,t)=u(\xi(z,t))$ (3.10), we solve $x=\xi_1=ze^t, y=\xi_2=tze^t$ for $z$ and $t$, with $x,y$ being given, Notice that $y/x = t$ and so $z=xe^{-t}=xe^{-y/x}$. By (3.10), $u(x,y)=v(z,t)=(xe^{-y/x})^2e^{y/x}+e^{y/x}-1=x^2e^{-y/x}+e^{y/x}-1$.  It is readily checked that $u$ solves our Cauchy problem for $x \neq 0. \qed$
% Theorem 3.5
{\bf 3.5T} Let $S=g(\Omega)$ be a hypersurface in $\R^n$. Let $\xi_1, \dots, \xi_n, v$ be a solution of the characteristic system (ODE) $\{\partial_t \xi_j=a_j(\xi,v), j=1,\dots, n, \partial_t v=c(\xi, v)\}$ on $V \times I$, (IC) $\{\xi(z,0)=g(z), v(z,0)=u_0(g(z))\} z \in V$, where $V$ is an open subset of $\Omega \subset \R^{n-1}$ and $I$ an open interval containing 0. Suppose that $v$ is differentiable on $V \times I$ and that there exists some open set $U$ in $\R^n$ such that $\xi=(\xi_1, \dots, \xi_n)$ is one-to-one and onto from $V\times I$ to $U, U \cap S = g(V)$, and that the inverse $\xi^{-1}$ is differentiable on $U$. Then the function $u: U\ra \R$ defined by $u(x)=v(\xi^{-1}(x)), x\in U$, is a solution of $\sum_{j=1}^na_j(x,u)\partial_ju=c(x,u), x \in U, u(x)=u_0(x), x\in U \cap S$. If $c, a_, \dots , a_n$ are partially differentiable in all variables and these partial derivatives are continuous, then $u$ is the unique solution. $\qed $
% Theorem 3.7
{\bf 3.7T} Let $S=g(\Omega)$ be a hypersurface in $\R^n$ with $g: \Omega \ra \R^n$, and $u_0: S\ra \R$. Let $\breve{z} \in \Omega$ and $\breve{x}=g(\breve{z})$. Assume that $g$ and $u_0 \circ g$ are continuously differentiable in an open neighborhood of $\breve{z}$ contained in $\Omega$. Further let $a_1, \dots, a_n, c$ be defined and continuously differentiable in an open neighborhood of $(\breve{x}, u_0(\breve{x}))$ in $\R^{n-1}$. Finally let det$(g'(\breve{z}), a(\breve{x}, u_0(\breve{x}))) \neq 0$ with $g'(z)=\begin{pmatrix}
  \partial_1g_1(z) &  \cdots &  \partial_{n-1}g_1(z) \\
  \vdots& &\vdots\\
  \partial_1g_n(z) &  \cdots &  \partial_{n-1}g_n(z) 
 \end{pmatrix}$ and $a(x,v)=
 \begin{pmatrix}
  a_1(x,v)  \\
  \vdots\\
   a_n(x,v) 
 \end{pmatrix}$. Then there exists an open neighborhood $U$ of $\breve{x}$ and a uniquely determined function $u: U\ra \R$ such that $\sum_{j=1}^n a_j(x,u)\partial_ju=c(x,u), x \in U, u(x)=u_0(x), x\in U \cap S$. We call the determinant in this theorem the characteristic determinant.
 {\bf Eq (3.17)} (PDE) $\partial u / \partial t + \sum_{j=1}^{n-1} b_j(t,u)\partial u / \partial y_j = \gamma u, y \in \R^{n-1}, t>0$ (IC) $u(y,0)=u_0(y), y \in \R^{n-1}$. 
 % Theorem 3.11
{\bf 3.11T} Let $b: \R \times [0, \infty) \ra \R$ be continuous and have continuous partial derivatives $b_u$. Further let $u_0$ be continuously differentiable.  Assume that $T>0$ and $\zeta (z,t) \ra \pm \infty, z \ra \pm\infty, t \in [0,T)$, and $\zeta_z(z,t)>0$ for all $z \in \R$ and $t \in [0,T)$.  Then the Cauchy problem (3.17) has a unique solution on $\R \times [0, T)$. The solution $u$ satisfies $u(\zeta (z, t), t)=u_0(z)e^{\gamma t}, z \in \R, t \in [0, T)$. {\it Proof}. It follows from the preceeding considerations that, for fixed $t \in [0,T)$, the function $\zeta(\cdot, t)$ is bijective from $\R$ to $\R$. So there exists a function $\phi: \R \times [0,T) \ra \R$ such that $\zeta(\phi(z,t), t)=z, \phi(\zeta(z,t),t)=z, z \in \R, t \in [0,T)$. It follows from our assumptions that $\zeta$ is continuously differentiable.  By the implicit function theorem, $\phi$ is continuously differentiable.  Define $u(y,t)=v(\phi(y,t),t)$. By Theorem 3.5, with $\xi(z,t)=(\zeta(z,t),t)$ and $\xi^{-1}(y,t)=(\phi(y,t),t)$, $u$ is differentiable and satisfies (3.17) on $\R \times [0,T). \qed$
% Corollary 3.12
{\bf 3.12C} Let $b: \R \times [0, \infty) \ra \R$ be continuous and have continuous partial derivatives $b_u$ and let $u_0: \R \ra \R$ be continuously differentiable.  Assime that $b_u \geq 0$ on $\R \times [0, T)$ and $u_0' \geq 0$ on $\R$ (or $b_u \leq 0$ and $u_0' \leq 0$). Then there exists a unique solution to (3.17) on $\R \times [0, \infty)$. 
{\bf d'Alembert's solution} $u(x,t)=(1/2)(f(x+ct)+f(x-ct)+(1/c)\int_{x-ct}^{x+ct}g(y)dy)$. {\it Proof}. Let $z \geq 0$. Then $b(s,u)$ is an increasing function of $u$ and $u_0$ is an increasing function and, by (3.20), $\zeta(z,t)\geq z+\int_0^tb(s,u_0(0)e^{\gamma s})ds \ra \infty, z \ra \infty$. Let $z \leq 0$. Then by the same toekn, $\zeta(z,t)\leq z+\int_0^tb(s,u_0(0)e^{\gamma s})ds \ra -\infty, z \ra -\infty$. Further, by (3.23), $\zeta_z(z,t)\geq 1$. The statemet now follows frim Theorem 3.11. $\qed$
{\bf 3.13L} The extended $f$ is $2L$-periodic and odd around 0 and $L$. {\it Proof}. By construction, $f$ is $2L$-periodic.  Indeed, let $x \in \R$. Then $x=y+2kL$ with $-L \leq y \leq L$ and $k \in \Z$. By the extension, $f(x+2L)=f(y+2(k+1)L)=f(y)=f(y+2kL)=f(x)$. Further $f(-x)=f(-y-2kL)=f(-y)=-f(y)=-f(x)$. So $f$ is odd around 0. $f$ is also odd around $L$, i.e. $f(L+x)=-f(L-x), x \in \R$. Indeed, since $f$ is odd about 0 and $2L$-periodic, $f(L+x)=-f(-L-x)=-f(L-x). \qed$
% Theorem 3.14
{\bf 3.14T} Let $f,g: [0,L] \ra \R$. Extend $f$ and $g$ in an odd and $2L$-periodic fashion.  Then the d'Alembert formula provides a solution of the vibrating string equations provided that $f$ is twice differentiable, $g$ is once differentiable, and $f(0)=0=f(L), f''(0)=0=f''(L), g(0)=0=g(L)$. {\bf Proof}. As we mentioned before,the conditions for $f$ and $g$ imply that their extensions to $\R$ are twice and once differentiable, respectively.  So the d'Alembert formula provides a solution to the PDE and the initial conditions.  We check the boundary condition at $L, u(L,t)=(1/2)(f(L+ct)+f(L-ct))+(1/2c)\int_{L-ct}^{L+ct}g(s)ds$. Since $f$ is odd around $L$, let $s = r+L, u(L,t)=(1/2c)\int_{-ct}^{ct}g(L+r)dr=(1/2c)\int_0^{ct}g(L+s)+g(L-s))ds$ after splitting the integral at 0 and changing of variables.  Since $g$ is odd around $L, u(x,t)=0$. The boundary condition at $x=0$ is checked similarly $\qed$ 
{\bf Inhomogeneous wave equation} $u(x,t)=(1/2c)\int_0^t(\int_{x-c(t-s)}^{x+c(t-s)}\phi(\rho,s)d\rho)ds$.
% Leibniz rule
{\bf Leibniz rule} $d/dx \int_{g(x)}^{h(x)}f(t)dt=f(h(x))h'(x)-f(g(x))g'(x)$
% Integration by parts
{\bf Int by parts} $\int u dv=uv-\int v du$
% Exercise 3.1.1
{\bf E3.1.1} (a) Let $f:\R_+ \ra \R$ be differentiable.  Show: The function $u: \R^2 \ra \R$ defined by $u(x,y)=f(x^2+y^2)$ satisfies the PDE $yu_x-xu_y=0$. (b) Assume that a differentiable function $u:\R^2 \ra \R$ satisfies the PDE $yu_x-xu_y=0$. Show: $u(x,y)=f(x^2+y^2)$ for all $x,y \in \R$ with some function $f:\R_+\ra \R$.  Hint:  Consider $w(z,t)=u(z\cos t,z \sin t)$.  Proof: (a) Define $u(x,y)=f(x^2+y^2)$ for $x,y \in \R$.  Then $yu_x-xu_y=y2xf'-x2yf'=0$. So $u$ is a solution of the PDE. (b) Let $u$ be a solution of the PDE.  Set $w(z,t)=u(z\cos t,z \sin t)$. Then $\partial_tw(z,t)=u_x(z\cos t,z \sin t)(-z \sin t) + u_y(z\cos t,z \sin t)(z \cos t)=0.$ So $w(z,t)=\tilde{f}(z)$ with an appropriate function $f$ and $u(z \cos t,z \sin t)=f(z)$. If $x = z \cos t$ and $y = z \sin t$, then $z^2 = x^2+y^2$. So $u(x,y)=\tilde{f}(\sqrt{x^2+y^2})=f(x^2+y^2)$ with $f(r)=\tilde{f}(\sqrt{r}). \qed$
% Exercise 3.1.2
{\bf E3.1.2} Solve the Cauchy problem $-yu_x+xu_y=0, u(x,x^2)=x^3$. {\bf Solution}. The curve $y=x^2$ is parameterized by $g(z)=(z,z^2)'$. The characteristic equations are $\partial_r\xi_1=-\xi_2, \xi_1(z,0)=z, \partial_r\xi_2=\xi_1, \xi_2(z,0)=z^2, \partial_rv=0, v(z,0)=z^3$. We solve the last equation to get $v=c$ and initial conditions gives $v=z^3$. We look at the first two equations, $\partial_r^2 \xi_1=-\xi_1$.  The general solution of this linear second order PDE is $\xi_1(z,r)=c_1 \cos r+c_2 \sin r$. Using initial conditions we get $\xi_1(z,0)=z=c_1 \cos (0)+c_2 \sin (0)=c_1\implies c_1=z. \; \partial_r\xi_1(z,r)=-z\sin r + c_2 \cos r = -\xi_2$ and $\xi_2(z,0)=z^2$ so $-z\sin (0) + c_2 \cos (0)=-z^2 \implies c_2=-z^2$. So we solve $x=z \cos r-z^2\sin r, y=zsinr +z^2 \cos r$. We try $x^2+y^2=z^2 \cos^2r-2z^3\cos r\sin r+z^4\sin^2r+z^2 \sin^2r+2z^3\cos r\sin r+z^4\cos^2r=z^2+z^4$. So $z^4+z^2-(x^2+y^2)=0$. Notice that this is a quadratic equation in $z^2$ so $z^2=(-1 \pm \sqrt{1+4(x^2+y^2)})/2 \implies z=\sqrt{(-1 \pm \sqrt{1+4(x^2+y^2)})/2}$ which gives $v=((-1 \pm \sqrt{1+4(x^2+y^2)})/2)^{3/2}$.  We check initial conditions for the sign. $((-1 \pm \sqrt{1+4x^2+4x^4)})/2)^{3/2}=((-1 \pm \sqrt{(2x^2+1)(2x^2+1)})/2)^{3/2}=((-1 \pm (2x^2+1))/2)^{3/2}$.  We take the positive to get $(x^2)^{3/2}=x^3$ so $u(x,y)=((-1 \pm \sqrt{1+4(x^2+y^2)})/2)^{3/2}$.
% Exercise 3.1.5
{\bf E3.1.5} Solve $-x_2\partial_1u+x_1\partial_2u=u$ on $\R^2,  u(x_1,0)=u_0(x_1^2), x_1 \in \R$. Answer:  $u=u_0(x_1^2+x_2^2)$ exp(arctan$(x_2/x_1))$.  Solution. The hypersurface (in this case a curve) is parameterized by $g(z)=(z; 0)$. The equations for the characteristic curves are $\partial_r \xi_1=-\xi_2, \xi_1(z,0)=z, \partial_r \xi_2=\xi_1, \xi_2(z,0)=0, \partial_r v = v, v(z,0)=u_0(z^2)$. Hence $\partial_r^2\xi_1=-\xi_1,\xi_1(z,0)=z, \partial_r\xi_1(z,0)=0$. The general solution of this linear second order ODE is $\xi_1(z,r)=c_1(z)\cos(r)+c_2(z)\sin(r)$. Using the initial conditions we find,  $\xi_1(z,r)=z\cos r$, and $\xi_2(z,r)=-\partial_r\xi_1(z,r)=z\sin r$. Finally $v(z,r)=u_0(z^2)e^r$.  From $x_1=z\cos r, x_2=z\sin r$ we have $z^2=x_1^2+x_2^2, x_2/x_1=\tan r$. This implies the above answer. $\qed$
%Exercise 3.1.7
{\bf E3.1.7} Determine the solution of $u=u(y,t)$ of $yu_y+uu_t=t, y,t \in \R, u(y,0)=1, y\in \R$. {\bf Solution}. Characteristic curves are $\partial_r\xi_1=\xi_1, \xi_1(z,0)=z, \partial_r\xi_2=v, \xi_2(z,0)=0, \partial_rv=\xi_2,  v(z,0)=1$. We solve the first equation, $\xi_1=c_1e^r$ with initial conditions we have $\xi_1=ze^r$.  The general solution of the second two equations is $\xi_2 = c_1 \cosh r+c_2 \sinh r, v = -c_1 \sinh r + c_2 \cosh r$.  When we apply the initial conditions we get $\xi_2=\sinh r, v=\cosh r$.  Now we solve $y=ze^r$ and $t = \sinh r$. We apply identities to get $2x_2=e^r-e^{-r}$.  We multiply through by $e^r$ and rearrange to get $(e^r)^2-2x_2(e^r)-1=0$.  This is a quadradic equation in $e^r$ so we get $e^r=(1/2)2t\pm \sqrt{4t^2-4(1)(-1)}=t\pm \sqrt{t^2+1}$.  $u(y,t)=v(z,r)=\cosh r=(1/2)e^r+e^-r)=(1/2)(t\pm \sqrt{t^2+1}+(t\pm \sqrt{t^2+1})^{-1})$. We check the initial condition and see that we have $u(y,t)=(1/2)(t+ \sqrt{t^2+1}+(t+ \sqrt{t^2+1})^{-1})$ which simplifies to $\sqrt{t^2+1}$.
% This one isn't in our book
{\bf E3.1.X} Solve $-x_2\partial_1u+x_1\partial_2u=u$ on $\R^2,  u(z,z)=v_0(z^2), z \in \R$, with $v_0: \R \ra \R$. Solution. The hypersurface (in this case a curve) is parameterized by $g(z)=(z; z)$. The equations for the characteristic curves are $\partial_r \xi_1=-\xi_2, \xi_1(z,0)=z, \partial_r \xi_2=\xi_1, \xi_2(z,0)=z, \partial_r v = v, v(z,0)=v_0(z^2)$. Hence $\partial_r^2\xi_1=-\xi_1,\xi_1(z,0)=z, \partial_r\xi_1(z,0)=0$. The general solution of this linear second order ODE is $\xi_1(z,r)=c_1(z)\cos(r)+c_2(z)\sin(r)$ and $\xi_2(z,r)=-\partial_r\xi_1(z,r)=c_1 \sin(r)-c_2 \cos(r).$  Finally $v(z,r)=v_0(z^2)e^r$.  From the initial conditions, $z = c_1(z), c_2(z)=-z$.  So $\xi_1(z,r)=z(\cos r - \sin r), \xi_2(z,r)=z(\cos r+\sin r)$. From the differential equations and initial conditions for $\xi$, we find $\xi_1^2 + \xi_2^2=2z^2$.  To find the inverse of $\xi$, we solve $x_1=z(\cos r - \sin r), x_2=z(\cos r+\sin r)$.  We already know $x_1^2 + x_2^2=2z^2$. Further $x_1+x_2=2z\cos r, x_2-x_1=2z\sin r$, and so $\tan r=(x_2-x_1)/(x_2+x_1)$. We obtain $u(x_1, x_2)=v_0((1/2)(x_1^2+x_2^2))exp(arctan((x_2-x_1)/(x_2+x_1)). \qed$
% Exercise 3.1.10
{\bf E3.1.10} Solve $\sum_{j=1}^nx_j^2\partial_ju=\alpha u, u(x_1, \dots, x_{n-1},b)=v_0(x_1, \dots, x_{n-1}), x_1, \dots, x_{n-1} \in \R,$ where $v_0: \R^{n-1} \ra \R$ is a given function and $b>0$ and $\alpha$ are given real numbers. Where is the solution defined?  Determine the characteristic determinant and ponder whether there is a connection between your result and where the solution is defined. Solution.  The equations for the characteristic curves take the form $\partial_t\xi_j(z,t)=\xi_j^2(z,t), \xi_j(z,0)=z_j, j=1,\dots, n-1, \xi_n(z,0)=b. \partial_tv(z,t)=\alpha v(z,t), v(z,0)=u_0(z)$. The equations are solved by $\xi_j(z,t)=1/((1/z_j)-t), z_j \neq 0, \xi_j(z,t)=0, z_j=0, j=1,\dots, n-1, \xi_n(z,t)=1/((1/b)-t), v(z,t)=u_0(z)e^{\alpha t}$. In order to find the inverse function of $\xi$, we solve the system $x_j=1/((1/z_j)-t), j=1,\dots, n-1, x_n=1/((1/b)-t)$. Hence $t = (1/b)-(1/x_n)$ and $z_j=1/((1/x_j)+t)=1/((1/x_j)-(1/x_n)+(1/b))=x_j/(1-(x_j/x_n)+(x_j/b))$. Notice that the last expression gives us $z_j=0$ iff $x_j=0$. As $u(x)=v(z,t)$ we obtain $u(x)=u_0((x_j/(1-(x_j/x_n)+(x_j/b)))_{1\leq j\leq n-1})\exp ((\alpha/b)-(\alpha/x_n))$.  Since the initial condition is posed at $x_n=b>0$ and $x_n \neq 0$ to make the solution defined, we impose $x_n>0$ on the domain of definition.  Further, if $x_n \neq b$, we require $x_j \neq (x_nb)/(b-x_n), j=1, \dots, n-1. \qed$
% Exercise 3.1.12
{\bf E3.1.12} Solve $(y+x)u_x+(y-x)u_y=u, u=1$ on the circle $x^2+y^2=1$.  Proof. The characteristic system is (for the time being we ignore the initial conditions) $\partial_t\xi_1=\xi_1+\xi_2, \partial_t\xi_2=-\xi_1+\xi_2, \partial_t v=v$. The first two equations form a linear subsystem with matrix $A=[1 \;1;-1\; 1]$. We solve the characteristic equation $0=[(1-\lambda) \;1;-1\; (1-\lambda)]=(\lambda-1)^2 +1$. The solutions of the characteristic equation are $\lambda = 1 \pm i$. So $\xi_1$ is of the form $\xi_1(z,t)=e^t(c_1(z)\cos t+c_2(z) \sin t)$. Since $\xi_2=\partial_t \xi_1-\xi_1, \xi_2(z,t)=e^t(-c_1(z)\sin t+c_2(z) \cos t)$. We parameterize the initial surface by $[\cos z ; \sin z]=g(z)=\xi(z,0)$. This yields $c_1(z)=\cos z, c_2(z) = \sin z$ and $\xi_1(z,t)=e^t(\cos z \cos t + \sin z \sin t)=e^t \cos(z-t), \xi_2(z,t)=e^t(- \cos z \sin t+\sin z \cos t) = e^t \sin(z-t)$. For $v$ we obtain, $v(z,t)=e^t$. To find $u$, we solve $x = e^t \cos(z-t), y =  e^t \sin(z-t).$ This yields $x^2 + y^2 = (e^t)^2$. So $u(x,y)= \pm \sqrt{x^2+y^2}.$ Because $u=1$ on the circle with radius $1, u(x,y)= \sqrt{x^2+y^2}.$
% Exercise 3.1.14
{\bf E3.1.14} Solve $\partial_1u+u\partial_2u=0, u(x_1,x_2)=\gamma$ on the line $x_1=x_2$. For which $\gamma$ can you solve the problem?  Determine the characteristic determinant and ponder whether there is a connection. Proof.  By inspection, $u(x_1,x_2)=\gamma$ for all $x_1, x_2 \in \R$ is a solution.  To check whether this is the only solution, we solve the characteristic system $\partial_t\xi_1(z,t)=1, \xi_1(z,t)=z, \partial_t\xi_2(z,t)=v, \xi_2(z,t)=z, \partial_tv(z,t)=0, v(z,0)=\gamma$. So $\xi_1(z,t)=t+z, v(z,t)=\gamma, \xi_2(z,t)=\gamma t+z$. The same proof as for Proposition 3.1 shows that $u(\xi(z,t))=v(z,t)=\gamma$. So any solution only takes the value $\gamma$. The characteristic determinant is given by $[1 \; 1; 1 \; \gamma] = \gamma-1$. While we cannot invert $\xi$ if $\gamma=1$, in this case a zero characteristic determinant does not indicate that there is a problem with existence or uniqueness. $\qed$.
% Exercise 3.1.15
{\bf E3.1.15} Determine all solutions $u=u(x_1,x_2)$ of $(1-u)\partial_{x_1} u+(1+u)\partial_{x_2} u=1,  x_1, x_2 \in \R, u(x_1, x_2)=0,  x_1=x_2$. Where are the solutions defined?  Interpret your results in the light of the general local existence theorem. {\it Proof}. We identify $g(z)=(z,z), z \in \R$ and $u_0(z,z)=0$.The characteristic system is $\partial_t \xi_1 =1-v, \xi_1(z,0)=z, \partial_t \xi_2 =1+v, \xi_2(z,0)=z, \partial_t v =1, v(z,0)=0$. We solve the equation for $v$ and get $v=t+c_v$.  With initial conditions this gives us $v=t$. We put this into the equations for $\xi_1$ and $\xi_2$ to get $\partial_t \xi_1=1-t \implies \xi_1=c_1+t-t^2/2, \partial_t \xi_2=1+t \implies \xi_1=c_1+t+t^2/2$. When we add the initial conditions we get $\xi_1 = z+t-t^2/2$, and $\xi_2=z+t+t^2/2$. To find $u$ we solve $x_1= z+t-t^2/2$ and $x_2=z+t+t^2/2. x_2-x_1 = t^2 \implies t=\pm \sqrt{x_2-x_1}$.From our equation above we have that $v=t$ and so $u(x)=\pm \sqrt{x_2-x_1}$.  These solutions are only defined where $x_2 \geq x_1$.  In the light of the general local existence theorem we find the determinant of the characteristic matrix. $det[1\; 1-u; 1 \; 1+u ] =1+u-(1-u)=2u$. Since $u(x_1, x_2)=0$ when $x_1=x_2$, this equals zero when  $x_1=x_2$.  So the assumptions of the general local existence theorem are not met and therefore we can have two solutions. 
% Exercise 3.2.1
{\bf E3.2.1}. Consider the Cauchy problem $\partial_t u +  b(t,u)\partial_y u = -\alpha u, \quad t > 0, y \in \R, u(y,0)=u_0(y)$ with $\alpha > 0$. Assume the following properties for the given functions $b: \R_+ \times \R \ra \R, u_0: \R \ra \R: b, u_0$ are continuously differentiable, $|b_u(t,u)| \leq c_1, |u_0'(y)| \leq c_2$ for all $y, t, u \in \R$ where $c_1, c_2$ are positive constants satisfying $c_1c_2 \leq \alpha$.  Show:  There exists a solution $u = u(y,t)$ which is defined for all $t \geq 0, y \in \R$. {\bf Solution}. This is a great candidate for Theorem 3.11.  We have $\zeta(z,t)=z + \int_0^t b(s,u_0(z)e^{-\alpha s})ds,$ and $\zeta_z(z,t)=1+u_0'(z) \int_0^t b_u(s,u_0(z)e^{-\alpha s})e^{-\alpha s}ds.$ Now we apply the properties of absolute value to get $\zeta_z(z,t)\geq 1-|u_0'(z)| \int_0^t |b_u(s,u_0(z)e^{-\alpha s})|e^{-\alpha s}ds.$ Now we apply the given assumptions and do some manipulation $\zeta_z(z,t)\geq 1-c_1 c_2 \int_0^t e^{-\alpha s}ds=1- (c_1 c_2)/\alpha (1- e^{-\alpha t})=1- (c_1 c_2)/\alpha + (c_1 c_2)/\alpha  e^{-\alpha t}.$ And so by our assuption that $c_1 c_2 \leq \alpha$ we have that $\zeta_z(z,t)>(c_1 c_2)/\alpha e^{-\alpha t}\geq e^{-\alpha t} >0$, for $z \in \R$ and $t \geq 0.$ Now we use the mean value theorem.  For for $z \in \R,$ with some $\tilde{z}$ betwen 0 and $z,\zeta(z,t)=\zeta(0,t)+z \zeta_z(\tilde{z},t).$ And so for $z > 0$, we have that $\zeta(z,t) \geq \zeta(0,t)+z   e^{-\alpha t}.$ Therefore $\zeta(z,t) \ra \infty$ as $z \ra \infty$. Moreover, for $z < 0, \zeta(z,t) \leq \zeta(0,t)+z  e^{-\alpha t}.$ Therefore $\zeta(z,t) \ra -\infty$ as $z \ra -\infty$. And so by Theorem 3.11, there exists a solution $u = u(y,t)$ which is defined for all $t \geq 0, y \in \R. \qed$.
% Exercise 3.2.2
{\bf E3.2.2} Consider the Cauchy problem $\partial_tu+\cos(wt)u\partial_xu=0, u(x,0)=u_0(x)$. Assume that $u_0$ is continuously differentiable on $\R$ and sup$_x|u_0'(x)|\leq M$ for some $M>0$. (a) Show that the solution exists for all $t \geq 0$ provided that $w$ is large enough. (b) What can be done if $w$ is not sufficiently large?  Solution.  In order to apply Theorem 3.11, we identify $b(t,u)=\cos(wt)u, u_0(y)=f(y)$. By (3.20) $\zeta(z,t)=z + \int_0^t \cos(ws)u_0(z)ds=z+(1/w)\sin(wt)u_0(z)$. Further $\zeta_z(z,t)=1+u_0'(z)\int_0^t \cos (ws)ds=1+(u_0'(z)/w)\sin(wt)$. (a) $\zeta_z(z,t)\geq 1 - (|u_0'(z)|/w)|\sin(wt)|\geq 1-(M/w)$. Choose $w > M$. Then $\zeta_z(z,t)>0$ for all $z \in \R, t \geq 0$. Let $t \geq 0, z \in \R$. By the mean value theorem $\zeta (z,t)=\zeta(0,t)+z\zeta_z(\tilde{z},t)$ with some $\tilde{z}$ between 0 and $z$ (which depends on $z$ and $t$). If $z \geq 0, \zeta(z,0)\geq \zeta(z,0)+z(1-(M/w))\ra \infty, z \ra \infty$. If $z \leq 0, \zeta(z,0)\leq \zeta(z,0)+z(1-(M/w))\ra -\infty, z \ra -\infty$. So, by Theorem 3.11, there exists a solution $u$ on $\R \times [0,\infty)$. (b) Alternatively, by (3.20), $\zeta_z(z,t)=1+u_0'(z)\int_0^t \cos (ws)ds\geq 1-Mt$. Choose $T = 1/M$. Then $\zeta_z(z,t)>0$ for all $t \in [0,T)$. Similarly as in (a), $\zeta(z,t)\ra \pm \infty$ as $z \ra \pm \infty$. By Theorem 3.11, there exists a unique solution $u$ on $\R \times [0,1/M). \qed$
% Exercise 3.3.2
{\bf E3.3.2} Solve the wave equation $\partial_t^2u-c^2\partial_x^2u=0, x,t \in \R, u(x,0)=f(x), u(cx,x)=g(x), x\in \R$ where $f,g: \R \ra \R$. State appropriate assumptions for $f$ and $g$ such that you really have a solution.  Proof. The general solution for this wave equation is $u(x,t)=F(x+ct)+G(x-ct)$. $F$ and $G$ are to be determined from the inital and diagonal data, $f(x)=u(x,0)=F(x)+G(x), g(x)=u(cx,x)=F(2cx)+G(0)$. Replacing $2cx$ by $x$ in the second equation, $f(x)=F(x)+G(x), g(x/(2c))=F(x)+G(0)$. We subtract the equations, $f(x)-g(x/(2c))=G(x)-G(0)$. We substitute this result into the first equation and rearrange, $F(x)=f(x)-G(x)=g(x/(2c))-G(0)$. We substitute this into the general solution, $u(x,t)=g((x+ct)/(2c))-g((x-ct)/(2c))+f(x-ct)$. For $u$ to be twice differentiable, we need $f$ and $g$ to be twice differentiable.  $u$ satisfies the diagonal condition iff $f(0)=g(0). \qed$
% Exercise 3.3.6
{\bf E3.3.6} Let $u$ be a solution of the wave equation $(\partial_t^2-c^2\partial_x^2)u(x,t)=0$. Show the ``parallelogram rule'' $u(A)+u(C)=u(B)+u(D)$ where $A,B,C$, and $D$ are arbitrary points of the form $C=(x,t), D=(x+cr,t+r), B=(x-cs,t+s), A=(x+cr-cs,t+r+s)$. Why is this formula called this way?  {\bf Proof}. Substitute in for the points $u(x+cr-cs,t+r+s)+u(x,t)=u(x-cs,t+s)+u(x+cr,t+r)$ Set $u(x,t)=F(x+ct)+G(x-ct)$. Then $F(x+cr-cs+ct+cr+cs)+G(x+cr-cs-ct-cr-cs)+F(x+ct)+G(x-ct)=F(x-cs+ct+cs)+G(x-cs-ct-cs)+F(x+cr+ct+cr)+G(x+cr-ct-cr) \implies F(x+2cr+ct)+G(x-2cs-ct)+F(x+ct)+G(x-ct)=F(x+ct)+G(x-2cs-ct)+F(x+2cr+ct)+G(x-ct)$ which are indeed equal. The slopes of the sides are $BC=(x-cs-x)/(t+s-t)=(-cs)/s=-c$, and $AD=(x+cr-cs-x-cr)/(t+r+s-t-r)=(-cs)/s=-c$ and so $BC$ and $AD$ are parallel lines. $CD=(x-x-cr)/(t-t-r)=(-cr)/(-r)=c$ and $BA=(x-cs-x-cr+cs)/(t+s-t-r-s)=(-cr)/(-r)=c$ and so $CD$ and $BA$ are parallel lines.  The slopes of adjacent lines are the additive inverse of each other.  $\qed$
%Exercise 3.3.9
{\bf E3.3.9} Let $u$ solve $(\partial_t^2-c^2\partial_x^2)u(x,t)=\phi(x,t),  x,t \in \R, u(x,0)=0, x \in \R, \partial_t(x,0)=0, x \in \R$. And $\tilde{u}$ solve $(\partial_t^2-c^2\partial_x^2)\tilde{u}(x,t)=\phi(x,t), x,t \in \R, \tilde{u}(x,0)=f(x), x \in \R, \partial_t\tilde{u}(x,0)=g(x), x \in \R$. Prove that $U = u + \tilde{u}$ solves $(\partial_t^2-c^2\partial_x^2)U(x,t)=\phi(x,t), x,t \in \R, U(x,0)=f(x), x \in \R, \partial_tU(x,0)=g(x), x \in \R$. This is a special case of the so-called principle of superposition.  It works here because the problem is linear. {\it Solution}. By assuption $U(x,t)=u(x,t)+\tilde{u}(x,t)$.  We differentiate with respect to $t$ to get  $\partial_t U(x,t)=\partial_t u(x,t)+\partial_t \tilde{u}(x,t)$.  It follows that  $\partial_t U(x,0)=\partial_t u(x,0)+\partial_t \tilde{u}(x,0)$. We rearrange the equations for $u$ and $\tilde{u}$ to get $\partial_t^2u(x,t)-c^2\partial_x^2u(x,t)=\phi(x,t), u(x,0)=0, \partial_tu(x,0)=0, \partial_t^2\tilde{u}(x,t)-c^2\partial_x^2\tilde{u}(x,t)=\phi(x,t), \tilde{u}(x,0)=f(x), \partial_t\tilde{u}(x,0)=g(x)$. We add these two sets of equations to get $\partial_t^2(u(x,t)+\tilde{u}(x,t))-c^2\partial_x^2(u(x,t)+\tilde{u}(x,t))=\phi(x,t), u(x,0)+ \tilde{u}(x,0)=f(x), \partial_tu(x,0)+\partial_t\tilde{u}(x,0)=g(x)$. And we get $\partial_t^2(U(x,t))-c^2\partial_x^2(U(x,t))=\phi(x,t), U(x,0)=f(x), \partial_tU(x,0)=g(x). \qed$
{\bf Extensions} Extend odd if boundary condition in $u$.  Extend even if boundary condition in $u_x$ or $u_t$. 
% Identities
{\bf Identities} $2\cos x=(e^{ix}+e^{-ix}), 2i\sin x=(e^{ix}-e^{-ix}), 2 \cosh x=(e^x+e^{-x}), 2\sinh x=(e^x-e^{-x}). \cosh^2 x-\sinh^2x=1$. 
{\bf Sum and Difference Formula} $\sin(A\pm B)=\sin A \cos B\pm \cos A \sin B$. $\cos(A\mp B)=\cos A \cos B\pm \sin A \sin B$. $\tan(A \pm B)=(\tan A\pm \tan B)/(1\mp \tan A \tan B)$.
{\bf Double Angle Formula}  $\sin(2A)=2 \sin A \cos A$. $\cos(2A)=\cos^2 A-\sin^2 A=2 \cos^2 A-1=1-2\sin^2 A$. $\tan(2A)=(2\tan A)/(1-\tan^2 A)$. 
{\bf Half Angle Formula} $\sin(A/2)=\pm \sqrt{(1-\cos A)/2}$. $\cos(A/2)=\pm \sqrt{(1+\cos A)/2}$. $\tan(A/2)=(1-\cos A)/(\sin A) = (\sin A)/(1+\cos A)$. 
{\bf Product to Sum} $\cos A \cos B=(1/2)(\cos(A+B)+\cos(A-B))$. $\sin A \sin B=(1/2)(\cos(A-B)-\cos(A+B)$. $\sin A \cos B=(1/2)(\sin(A+B)+\sin(A-B)$. 
{\bf Sum to Product} $\sin A\pm \sin B=2\sin((A\pm B)/2)\cos((A\mp B)/2)$. $\cos A - \cos B=-2\sin((A+B)/2)\sin((A-B)/2)$. $\cos A + \cos B=2\cos((A+B)/2)\cos((A-B)/2)$. 
{\bf Geometric Sum} $\sum_{k=1}^{\infty}q^k=q/(1-q)$. $\sum_{k=1}^n q^k=(q-q^{n-1})/(1-q)$. \\

{\bf General ODE Solutions}  $y''=y(t)\implies y=c_1e^{-t}+c_2e^t \qed \; dy/dt+p(t)y=g(t) \implies y=(\int u(t)g(t))/u(t) + c$ where $u(t)=$exp$(\int p(t)dt) \qed \; y'=x; x'=y \implies x=c_1 \cosh t + c_2 \sinh t, y=c_1\sinh t+c_2 \cosh t$ or $x=c_1e^t+c_2e^{-t}, y=c_1e^t-c_2e^{-t} \qed \; y'=-x; x'=y \implies y=c_1 \cos t + c_2 \sin t, x=c_1\sin t-c_2 \cos t \qed \; x'=x+y; y'=-x+y \implies x=e^t(c_1 \cos t+c_2 \sin t); y=e^t(-c_1\sin t +c_2 \cos t) \qed \; v'=\gamma v, v(z,0)=u_0 \implies v=u_0e^{\gamma t} \qed$
\hrule
\textbf{3.11.T}$\frac{\partial u}{\partial t}+\sum_{j=1}^{n-1}b_j(t,u)\frac{\partial u}{\partial y_j}=\gamma u$, $u(y,0)=u_0(y)$. $\zeta(z,t)=z+\int_0^tb(s,u_0(z)e^{\gamma s})ds,\zeta_z(z,t)=1+u'_0(z)\int_0^tb_u(s,u_0(z)e^{\gamma s})e^{\gamma s}ds$. Prove $\zeta\rightarrow\infty$ and $\zeta_z>0$. \textbf{Wave equation:} $\partial^2_tu(x,t)-c^2\partial^2_x=0\rightarrow u(x,t)=F(x+ct)+G(x-ct)$. \textbf{Vibrating String, 3.14.T:} $\partial^2_tu(x,t)-c^2\partial^2_x=0$, $u(x,0)=f(x)$, $\partial_tu(x,0)=g(x)$, $u(0,t)=0=u(L,t)$, $x\in[0,L],t\in\R\rightarrow$\textbf{d'Alembert formula} $u(x,t)=\frac{1}{2}\left(f\left(x+ct\right)+f\left(x-ct\right)\right)+\frac{1}{2c}\int_{x-ct}^{x+ct}g(s)ds$. \textbf{Inhomogeneous wave equation:} $\partial^2_tu(x,t)-c^2\partial^2_x=0$, $u(x,0)=0$, $\partial_tu(x,0)=0$, $x,t\in\R\rightarrow u=\frac{1}{2c}\int_0^t\int_{x-c(t-s)}^{x+c(t-s)}\phi(\rho,s)d\rho ds$. \textbf{Remember:} only the odd functions give $f(0)=0=f(L)$.
% Exercise 3.3.5
%{\bf E3.3.5} Solve the wave equation $\partial_t^2-c^2\partial_x^2=0, x,t \geq 0, u(x,0)=f(x), \partial_tu(x,0)=g(x), x\geq 0, \partial_xu(0,t)=h(t),t\geq 0$, for given functions $f,g,h$. Explain the properties $f,g,h$ should have such that the expression you obtain actually is a solution.  Solution. The general solution for this wave equation is $u(x,t)=F(x+ct)+G(x-ct)$. $F$ and $G$ are to be determined from the initial and boundary data. Differentiating $u$ we obtain $\partial_tu(x,t)=c(F'(x+ct)-G'(x-ct)), \partial_xu(x,t)=F'(x+ct)+G'(x-ct)$. Hence $f(x)=u(x,0)=F(x)+G(x), g(x)=\partial_t(x,0)=c(F'(x)-G'(x)), h(t)=\partial_xu(0,t)=F'(ct)+G'(-ct), t,x>0$.  The last equation can be rewritten as $h(x/c)=F'(x)+G'(-x), x>0$. Integrating we obtain $\int_0^xg(y)dy=c(F(x)-F(o)-G(x)+G(0)), \int_0^xh(y/c)dy=F(x)-F(0)-G(-x)+G(0)$. Summarizing we get $F(x)+G(x)=f(x), F(x)-G(x)=(1/c)\int_0^xg(y)dy+F(0)-G(0), G(-x)=-\int_0^xh(y/c)dy+f(x)-F(0)+G(0)$ for $x >0$.  Adding and subtracting the first two equations and substituting the result into the third we obtain for $x>0$ that $f(x)=(1/2)(f(x)+(1/c)\int_0^xg(y)dy+F(0)-G(0)), G(x)=(1/2)(f(x)-(1/c)\int_0^xg(y)dy-F(0)+G(0)),G(-x)=-\int_0^xh(y/c)dy-F(0)+G(0)+(1/2)(f(x)+(1/c)\int_0^xg(y)dy+F(0)-G(0))$. For $x-ct>0$ we get the usual d'Alembert formula: $u(x,t)=(1/2)(f(x+ct)+f(x-ct)+(1/c)\int_{x-ct}^{x+ct}g(y)dy)$. For $x-ct<0$ we obtain $u(x,t)=(1/2)(F(x+ct)+G(-(ct-x)=(1/2)(f(x+ct)+(1/c)\int_0^{x+ct}g(y)dy+F(0)-G(0))-\int_0^{ct-x}h(y/c)dy+(1/2)(f(ct-x)+(1/c)\int_0^{ct-x}g(y)dy+F(0)-G(0))-F(0)+G(0)$, i.e., for $ct-x > 0, u(x,t)=(1.2)(f(x+ct)+f(ct-x))-\int_0^{ct-x}h(y/c)dy+(1/(2c))(\int_0^{ct+x}g(y)dy+\int_0^{ct-x}g(y)dy)$. It is easy to see that $u$ is twice differentiable and satisifes the wave equation at $x-ct \neq 0$, provided that $f$ is twice differentiable and $g,h$ are once differentiable.  $u$ is twice differentiable at $x=ct$ iff the formulas for $G$ for positive and negative $x$ match for $x=0$. The two formulas match at 0, so $u$ is continuous.  We have that $G'(x)=(1/2)(f'(x)-(1/c)g(x)), -G'(-x)=-h(x/c)+(1/2)f'(x)+(1/(2c))g(x)$. This yields the same result at $x=0$ iff $f'(0)=h(0)$. So $u$ is differentiable at $x=ct$ iff $f'(0)=h(0)$. Further $G''(x)=(1/2)(f''(x)-(1/c)g'(x)), G(-x)''=-(1/c)h'(x/c)+(1/2)f''(x)+(1/(2c))g'(x)$. This yields the same result for $x=0$ iff $g'(0)=h'(0)$. Hence $u$ is twice differentiable at $x=ct$ iff $g'(0)=h'(0). \qed$
\end{multicols}
\end{document}