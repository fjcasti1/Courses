{\bf T 5.8}. Let $u$ be the sol of the heat eq with zero boundary conditions and initial data $f \in L^2([0,L],\R)$. Then $||u(\cdot, t)|| \leq ||f||e^{-a\lambda_1^2 t}, t \geq 0$. 
%{\it Proof}. With $\{v_m\}$ being the orthonormal basis of sine functions, $u(\cdot, t)=\sum_{m=1}^{\infty}\langle f, v_m \rangle v_m e^{-a \lambda_m^2 t}$. By orthonormality and Parseval's relation, $||u(\cdot, t)||^2 = \sum_{m=1}^{\infty}|\langle f, v_m \rangle |^2 e^{-2a \lambda_m^2 t}\leq e^{-2a \lambda_1^2 t}\sum_{m=1}^{\infty}|\langle f, v_m \rangle|^2=e^{-2a \lambda_1^2 t} ||f||^2$. This implies the assertion$\qed$